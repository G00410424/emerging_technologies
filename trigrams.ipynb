{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Third-Order Letter Approximation Model\n",
    "In this task, we build a trigram model based on sequences of three consecutive characters from a text.\n",
    "We will:\n",
    "1. Read five books.\n",
    "2. Clean the text by removing unwanted characters.\n",
    "3. Remove the preamble and postamble of the books.\n",
    "4. Build a trigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading the File\n",
    "\n",
    "The function `read_file()` takes the file path of a text file as input and reads the entire content of the file. This is useful for loading the text of a book into memory so that we can process it later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the file from the given file path\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads the entire content of a file given the file path.\n",
    "    \n",
    "    :param file_path: Path to the file to be read\n",
    "    :return: Text content of the file as a string\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()  # Read all the content of the file\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Cleaning the Text\n",
    "\n",
    "The function `clean_text()` cleans the text by:\n",
    "- Removing all characters except for letters, spaces, and full stops.\n",
    "- Converting all letters to uppercase.\n",
    "\n",
    "This ensures that we are working with a standardized and clean text before building the trigram model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # Importing regular expressions for text cleaning\n",
    "\n",
    "# Step 2: Clean the text by removing unwanted characters and converting to uppercase\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the text by removing everything except letters, spaces, and full stops.\n",
    "    Converts all letters to uppercase.\n",
    "\n",
    "    :param text: The original text to be cleaned\n",
    "    :return: Cleaned text\n",
    "    \"\"\"\n",
    "    # Remove everything except letters (A-Z, a-z), spaces, and full stops using regular expressions\n",
    "    cleaned_text = re.sub(r'[^A-Za-z. ]', '', text)\n",
    "    # Convert the remaining text to uppercase for consistency\n",
    "    cleaned_text = cleaned_text.upper()\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Removing Preamble and Postamble\n",
    "\n",
    "Books from Project Gutenberg contain preamble and postamble text that we donâ€™t want to include in our trigram model. The `remove_preamble_postamble()` function cuts out everything before the start of the actual content and after the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove the preamble and postamble from the text\n",
    "def remove_preamble_postamble(text):\n",
    "    \"\"\"\n",
    "    Removes the preamble and postamble from a Project Gutenberg text.\n",
    "    \n",
    "    :param text: The text that contains the preamble and postamble\n",
    "    :return: Text with the preamble and postamble removed\n",
    "    \"\"\"\n",
    "    # Find the start of the actual book content\n",
    "    start_index = text.find(\"START OF THIS PROJECT GUTENBERG\")\n",
    "    # Find the end of the actual book content\n",
    "    end_index = text.find(\"END OF THIS PROJECT GUTENBERG\")\n",
    "\n",
    "    # If both start and end markers are found, remove everything outside the book content\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        text = text[start_index:end_index]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Building the Trigram Model\n",
    "\n",
    "We use the `build_trigram_model()` function to count the number of times each sequence of three consecutive characters (trigrams) appears in the text. This model is stored in a dictionary, where the keys are the trigrams and the values are the counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict  # Importing defaultdict to store trigram counts\n",
    "\n",
    "# Step 4: Build a trigram model\n",
    "def build_trigram_model(text):\n",
    "    \"\"\"\n",
    "    Creates a trigram model by counting occurrences of every sequence of three consecutive characters.\n",
    "    \n",
    "    :param text: The cleaned and processed text\n",
    "    :return: A trigram model as a dictionary with trigrams as keys and their counts as values\n",
    "    \"\"\"\n",
    "    trigram_model = defaultdict(int)  # Dictionary to store trigrams and their counts\n",
    "\n",
    "    # Loop through the text and extract trigrams (sequences of three characters)\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i+3]  # Extract three characters at a time\n",
    "        trigram_model[trigram] += 1  # Increment the count for this trigram\n",
    "\n",
    "    return trigram_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Processing All Books\n",
    "\n",
    "We now process each of the five books by:\n",
    "1. Reading the content of the book.\n",
    "2. Cleaning the text by removing unwanted characters and converting to uppercase.\n",
    "3. Removing the preamble and postamble.\n",
    "4. Building a trigram model for each book.\n",
    "\n",
    "Finally, we print the first 100 characters of the cleaned text and show the first 10 trigrams for each book.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 1: THE PROJECT GUTENBERG EBOOK OF PARIS    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED S\n",
      "[('THE', 1966), ('HE ', 1516), ('E P', 198), (' PR', 276), ('PRO', 249), ('ROJ', 95), ('OJE', 94), ('JEC', 173), ('ECT', 329), ('CT ', 156)]\n",
      "Book 2: THE PROJECT GUTENBERG EBOOK OF IN THE STRANGER PEOPLES COUNTRY    THIS EBOOK IS FOR THE USE OF ANYON\n",
      "[('THE', 9030), ('HE ', 9179), ('E P', 778), (' PR', 624), ('PRO', 450), ('ROJ', 92), ('OJE', 92), ('JEC', 146), ('ECT', 606), ('CT ', 281)]\n",
      "Book 3: THE PROJECT GUTENBERG EBOOK OF EVERYBODYS BUSINESS    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE I\n",
      "[('THE', 3661), ('HE ', 3420), ('E P', 305), (' PR', 329), ('PRO', 260), ('ROJ', 88), ('OJE', 88), ('JEC', 125), ('ECT', 306), ('CT ', 144)]\n",
      "Book 4: THE PROJECT GUTENBERG EBOOK OF CINDERELLAS PRINCE    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN\n",
      "[('THE', 1392), ('HE ', 1243), ('E P', 135), (' PR', 215), ('PRO', 169), ('ROJ', 89), ('OJE', 90), ('JEC', 94), ('ECT', 186), ('CT ', 119)]\n",
      "Book 5: THE PROJECT GUTENBERG EBOOK OF THE MUSGRAVE CONTROVERSY    THIS EBOOK IS FOR THE USE OF ANYONE ANYWH\n",
      "[('THE', 1470), ('HE ', 1198), ('E P', 277), (' PR', 295), ('PRO', 224), ('ROJ', 88), ('OJE', 88), ('JEC', 107), ('ECT', 224), ('CT ', 133)]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Process all the books and print the first 100 characters of each\n",
    "\n",
    "# List of file paths for the five books\n",
    "book_files = [\n",
    "    '/workspaces/emerging_technologies/Books/book1_paris.txt',\n",
    "    '/workspaces/emerging_technologies/Books/book2_stranger_peoples_country.txt',\n",
    "    '/workspaces/emerging_technologies/Books/book3_everybodys_business.txt',\n",
    "    '/workspaces/emerging_technologies/Books/book4_cinderellas_prince.txt',\n",
    "    '/workspaces/emerging_technologies/Books/book5_the_musgrave_controversy.txt'\n",
    "]\n",
    "\n",
    "# Loop through each book, process it, and print the first 100 characters\n",
    "for i, file_path in enumerate(book_files):\n",
    "    # Read the book content from the file\n",
    "    text = read_file(file_path)\n",
    "    # Clean the text by removing unwanted characters and converting to uppercase\n",
    "    cleaned = clean_text(text)\n",
    "    # Remove the preamble and postamble to focus on the actual content\n",
    "    cleaned = remove_preamble_postamble(cleaned)\n",
    "\n",
    "    # Print the first 100 characters from each book with a clear label\n",
    "    print(f\"Book {i+1}: {cleaned[:100]}\")  # Printing first 100 characters of each book\n",
    "\n",
    "    # Build the trigram model for the current book\n",
    "    trigram_model = build_trigram_model(cleaned)\n",
    "\n",
    "    # If you want to see the first 10 trigrams of each book, uncomment the next line\n",
    "    print(list(trigram_model.items())[:10])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
